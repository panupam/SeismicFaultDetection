{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7569ae1a-f2b6-4927-8240-95ec2072f567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3174, 1537)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.load('./faults/faulttrain1.npz')\n",
    "b['arr_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a27eb841-3dd5-4931-8048-f94efcc51bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3174, 1537)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.load(\"./faults/seistrain1.npz\")\n",
    "c['arr_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d58ce563-5f07-465f-9050-4dc62f4d3afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3174, 1537)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['arr_0'][50:80].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3646010-b893-4920-a7cf-b8ce853bc477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainseis = c['arr_0'][:50]\n",
    "valseis = c['arr_0'][50:80]\n",
    "testseis = c['arr_0'][80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69629886-77e0-4cf9-8b7b-27b8c4ff4e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('./faults/trainseis.npy',trainseis)\n",
    "np.save('./faults/valseis.npy',valseis)\n",
    "np.save('./faults/testseis.npy',testseis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a10aa953-3cfc-428a-bc7e-f0bea648105a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainfault = b['arr_0'][:50]\n",
    "valfault = b['arr_0'][50:80]\n",
    "testfault = b['arr_0'][80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4921c407-3213-4447-aebb-463fb921b324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('./faults/ml_data/trainfault.npy',trainfault)\n",
    "np.save('./faults/ml_data/valfault.npy',valfault)\n",
    "np.save('./faults/ml_data/testfault.npy',testfault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436230df-f863-46a4-97bd-cae0c1d1a7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kl/gztfr05x5r9gbmdhs041ny0h0000gn/T/ipykernel_57549/2091789324.py:12: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-white')\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import time\n",
    "import cv2 \n",
    "import math\n",
    "from itertools import compress,product\n",
    "# from skimage import color # rgb order\n",
    "from skimage.util.shape import view_as_windows\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "plt.switch_backend('agg')\n",
    "import numpy as np  \n",
    "import scipy.signal\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, CLAHE,\n",
    "    ShiftScaleRotate, OpticalDistortion, GridDistortion, ElasticTransform,\n",
    "    RandomBrightnessContrast, IAASharpen, IAAEmboss, Flip, OneOf, Compose)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "def cross_entropy_loss_HED(prediction, label):\n",
    "    label = label.long()\n",
    "    mask = label.float()\n",
    "    num_positive = torch.sum((mask == 1).float()).float()\n",
    "    num_negative = torch.sum((mask == 0).float()).float()\n",
    "\n",
    "    mask[mask == 1] = 1.0 * num_negative / (num_positive + num_negative)\n",
    "    mask[mask == 0] = 1.0 * num_positive / (num_positive + num_negative)\n",
    "    cost = torch.nn.functional.binary_cross_entropy(\n",
    "            prediction.float(),label.float(), weight=mask, reduce=False)\n",
    "    return torch.sum(cost) #torch.mean(cost)\n",
    "\n",
    "def cross_entropy_loss_RCF(prediction, label):\n",
    "    label = label.long()\n",
    "    mask = label.float()\n",
    "    num_positive = torch.sum((mask==1).float()).float()\n",
    "    num_negative = torch.sum((mask==0).float()).float()\n",
    "\n",
    "    mask[mask == 1] = 1.0 * num_negative / (num_positive + num_negative)\n",
    "    mask[mask == 0] = 1.1 * num_positive / (num_positive + num_negative)\n",
    "    cost = torch.nn.functional.binary_cross_entropy(\n",
    "            prediction.float(),label.float(), weight=mask, reduce=False)\n",
    "    return torch.sum(cost) #torch.mean(cost)\n",
    "\n",
    "\n",
    "def split_Image(bigImage,isMask,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number):\n",
    "#     print(bigImage.shape)\n",
    "    if isMask==True:\n",
    "        arr = np.pad(bigImage,((top_pad,bottom_pad),(left_pad,right_pad)),\"reflect\")\n",
    "        splits = view_as_windows(arr, (splitsize,splitsize),step=stepsize)\n",
    "        splits = splits.reshape((vertical_splits_number*horizontal_splits_number,splitsize,splitsize))\n",
    "    else: \n",
    "        arr = np.pad(bigImage,((top_pad,bottom_pad),(left_pad,right_pad),(0,0)),\"reflect\")\n",
    "        splits = view_as_windows(arr, (splitsize,splitsize,3),step=stepsize)\n",
    "        splits = splits.reshape((vertical_splits_number*horizontal_splits_number,splitsize,splitsize,3))\n",
    "    return splits # return list of arrays.\n",
    "\n",
    "\n",
    "def recover_Image(patches: np.ndarray, imsize: Tuple[int, int, int], left_pad,right_pad,top_pad,bottom_pad, overlapsize):\n",
    "#     patches = np.squeeze(patches)\n",
    "    assert len(patches.shape) == 5\n",
    "\n",
    "    i_h, i_w, i_chan = imsize\n",
    "    image = np.zeros((i_h+top_pad+bottom_pad, i_w+left_pad+right_pad, i_chan), dtype=patches.dtype)\n",
    "    divisor = np.zeros((i_h+top_pad+bottom_pad, i_w+left_pad+right_pad, i_chan), dtype=patches.dtype)\n",
    "\n",
    "#     print(\"i_h, i_w, i_chan\",i_h, i_w, i_chan)\n",
    "    n_h, n_w, p_h, p_w,_= patches.shape\n",
    "    \n",
    "    o_w = overlapsize\n",
    "    o_h = overlapsize\n",
    "\n",
    "    s_w = p_w - o_w\n",
    "    s_h = p_h - o_h\n",
    "\n",
    "    for i, j in product(range(n_h), range(n_w)):\n",
    "        patch = patches[i,j]\n",
    "        image[(i * s_h):(i * s_h) + p_h, (j * s_w):(j * s_w) + p_w] += patch\n",
    "        divisor[(i * s_h):(i * s_h) + p_h, (j * s_w):(j * s_w) + p_w] += 1\n",
    "\n",
    "    recover = image / divisor\n",
    "    return recover[top_pad:top_pad+i_h, left_pad:left_pad+i_w]\n",
    "\n",
    "def recover_Image2(patches: np.ndarray, imsize: Tuple[int, int, int], left_pad,right_pad,top_pad,bottom_pad, overlapsize):\n",
    "#     patches = np.squeeze(patches)\n",
    "    assert len(patches.shape) == 5\n",
    "\n",
    "    i_h, i_w, i_chan = imsize\n",
    "    image = np.zeros((i_h+top_pad+bottom_pad, i_w+left_pad+right_pad, i_chan), dtype=patches.dtype)\n",
    "    divisor = np.zeros((i_h+top_pad+bottom_pad, i_w+left_pad+right_pad, i_chan), dtype=patches.dtype)\n",
    "\n",
    "#     print(\"i_h, i_w, i_chan\",i_h, i_w, i_chan)\n",
    "    n_h, n_w, p_h, p_w,_= patches.shape\n",
    "    \n",
    "    o_w = overlapsize\n",
    "    o_h = overlapsize\n",
    "\n",
    "    s_w = p_w - o_w\n",
    "    s_h = p_h - o_h\n",
    "\n",
    "    for i, j in product(range(n_h), range(n_w)):\n",
    "        patch = patches[i,j]\n",
    "        image[(i * s_h):(i * s_h) + p_h, (j * s_w):(j * s_w) + p_w] += patch\n",
    "#         divisor[(i * s_h):(i * s_h) + p_h, (j * s_w):(j * s_w) + p_w] += 1\n",
    "\n",
    "    recover = image / 4\n",
    "    return recover[top_pad:top_pad+i_h, left_pad:left_pad+i_w]\n",
    "\n",
    "#https://github.com/Vooban/Smoothly-Blend-Image-Patches\n",
    "def spline_window(window_size, power=2):\n",
    "    \"\"\"\n",
    "    Squared spline (power=2) window function:\n",
    "    https://www.wolframalpha.com/input/?i=y%3Dx**2,+y%3D-(x-2)**2+%2B2,+y%3D(x-4)**2,+from+y+%3D+0+to+2\n",
    "    \"\"\"\n",
    "    intersection = int(window_size/4)\n",
    "    wind_outer = (abs(2*(scipy.signal.triang(window_size))) ** power)/2\n",
    "    wind_outer[intersection:-intersection] = 0\n",
    "\n",
    "    wind_inner = 1 - (abs(2*(scipy.signal.triang(window_size) - 1)) ** power)/2\n",
    "    wind_inner[:intersection] = 0\n",
    "    wind_inner[-intersection:] = 0\n",
    "\n",
    "    wind = wind_inner + wind_outer\n",
    "    wind = wind / np.average(wind)\n",
    "    return wind\n",
    "\n",
    "\n",
    "cached_2d_windows = dict()\n",
    "def window_2D(window_size, power=2):\n",
    "    \"\"\"\n",
    "    Make a 1D window function, then infer and return a 2D window function.\n",
    "    Done with an augmentation, and self multiplication with its transpose.\n",
    "    Could be generalized to more dimensions.\n",
    "    \"\"\"\n",
    "    # Memoization\n",
    "    global cached_2d_windows\n",
    "    key = \"{}_{}\".format(window_size, power)\n",
    "    if key in cached_2d_windows:\n",
    "        wind = cached_2d_windows[key]\n",
    "    else:\n",
    "        wind = spline_window(window_size, power)\n",
    "        wind = np.expand_dims(np.expand_dims(wind, -1), -1)\n",
    "        wind = wind * wind.transpose(1, 0, 2)\n",
    "        cached_2d_windows[key] = wind\n",
    "    return wind\n",
    "\n",
    "def crop(variable, th, tw):\n",
    "        h, w = variable.shape[2], variable.shape[3]\n",
    "        x1 = int(round((w - tw) / 2.))\n",
    "        y1 = int(round((h - th) / 2.))\n",
    "        return variable[:, :, y1 : y1 + th, x1 : x1 + tw]\n",
    "    \n",
    "def strong_aug(p=1):\n",
    "    return OneOf([\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=1),\n",
    "        IAASharpen(p=1),\n",
    "        IAAEmboss(p=1),\n",
    "        RandomBrightnessContrast(p=1),\n",
    "        HorizontalFlip(p=1),\n",
    "        VerticalFlip(p=1),\n",
    "        Compose([VerticalFlip(p=1), HorizontalFlip(p=1)]),\n",
    "        ElasticTransform(p=1, alpha=400, sigma=400 * 0.05, alpha_affine=400 * 0.03),\n",
    "        GridDistortion(p=1),\n",
    "        OpticalDistortion(p=1)\n",
    "    ], p=p)\n",
    "\n",
    "#idea from https://www.kaggle.com/iezepov/fast-iou-scoring-metric-in-pytorch-and-numpy\n",
    "SMOOTH = 1e-6\n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    \n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "\n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))  # Will be zzero if both are 0\n",
    "\n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    return iou\n",
    "\n",
    "def iou_numpy(outputs: np.array, labels: np.array):\n",
    "\n",
    "    intersection = (outputs & labels).sum((0,1))\n",
    "    union = (outputs | labels).sum((0,1))\n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    return iou  # Or thresholded.mean()\n",
    "\n",
    "\n",
    "def crop2(variable, th, tw): # this is for crop center when outputs are 96*96\n",
    "        h, w = variable.shape[-2], variable.shape[-1]\n",
    "        x1 = int(round((w - tw) / 2.))\n",
    "        y1 = int(round((h - th) / 2.))\n",
    "        return variable[:, :, y1 : y1 + th, x1 : x1 + tw]\n",
    "\n",
    "#https://blog.csdn.net/qq_15602569/article/details/79565402 \n",
    "def acc_metrics(outputs, labels):\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    # TP    predict 和 label 同时为1\n",
    "    TP += ((outputs == 1) & (labels == 1)).sum()\n",
    "    # TN    predict 和 label 同时为0\n",
    "    TN += ((outputs == 0) & (labels == 0)).sum()\n",
    "    # FN    predict 0 label 1\n",
    "    FN += ((outputs == 0) & (labels == 1)).sum()\n",
    "    # FP    predict 1 label 0\n",
    "    FP += ((outputs == 1) & (labels == 0)).sum()\n",
    "    p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return p,r,F1,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13ce4929-8b84-4e34-a8f4-de2d20348d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import cmapy\n",
    "import time\n",
    "def process_raw_data(data_type, npy_data_name, npy_label_name, split_size, step_size,length):\n",
    "    \n",
    "    \n",
    "\n",
    "    # setting random seed\n",
    "    torch.manual_seed(1)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    time1 = time.time()\n",
    "\n",
    "    print(\"started reading\")\n",
    "    data_folder = \"\"\n",
    "    processed_data_folder = \"{}./processed_data\".format(data_folder)\n",
    "    original_data_folder = \"{}./faults/ml_data\".format(data_folder)\n",
    "\n",
    "\n",
    "    # loading training set\n",
    "    seismic_path = '{}/{}.npy'.format(original_data_folder,npy_data_name)\n",
    "    label_path = '{}/{}.npy'.format(original_data_folder,npy_label_name)\n",
    "    t_start = time.time()\n",
    "    seismic = np.load(seismic_path)\n",
    "    fault = np.load(label_path)\n",
    "    print(\"loaded data in {} sec\".format(time.time()-t_start))\n",
    "\n",
    "    # converting to IL, Z, XL order\n",
    "    seismic = np.moveaxis(seismic,-2,-1) \n",
    "    fault = np.moveaxis(fault,-2,-1)\n",
    "    seismic = (seismic-seismic.min(axis=(1,2), keepdims=True))/(seismic.max(axis=(1,2), keepdims=True)-seismic.min(axis=(1,2), keepdims=True))\n",
    "\n",
    "    print(seismic.shape, fault.shape)\n",
    "    print(seismic.max(),seismic.min(), fault.max(), fault.min())\n",
    "\n",
    "\n",
    "    IL, Z, XL = fault.shape\n",
    "\n",
    "    im_height = Z\n",
    "    im_width = XL\n",
    "    splitsize = split_size\n",
    "    stepsize = step_size\n",
    "    overlapsize = splitsize-stepsize\n",
    "    pixel_max = int(0.03*splitsize*splitsize)\n",
    "\n",
    "\n",
    "    hori_splits_number = int(np.ceil((im_width-overlapsize)/stepsize))\n",
    "    print(\"hori_splits\", hori_splits_number)\n",
    "    width_after_pad = stepsize*hori_splits_number+overlapsize\n",
    "    print(\"width_after_pad\", width_after_pad)\n",
    "    left_pad = int((width_after_pad-im_width)/2)\n",
    "    right_pad = width_after_pad-im_width-left_pad\n",
    "    print(\"l_pad,r_pad\",left_pad,right_pad)\n",
    "\n",
    "    vertical_splits_number = int(np.ceil((im_height-overlapsize)/stepsize))\n",
    "    print(\"vertical_splits\",vertical_splits_number)\n",
    "    height_after_pad = stepsize*vertical_splits_number+overlapsize\n",
    "    print(\"height_after_pad\",height_after_pad)\n",
    "    top_pad = int((height_after_pad-im_height)/2)\n",
    "    bottom_pad = height_after_pad-im_height-top_pad\n",
    "    print(\"top_pad,bot_pad\", top_pad,bottom_pad)\n",
    "\n",
    "\n",
    "    t_start = time.time()\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(0,length,1):\n",
    "        mask = fault[i]\n",
    "        splits = split_Image(mask, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,hori_splits_number)\n",
    "        t = (splits.sum((1,2)) < pixel_max)\n",
    "        no_label_element_index = list(compress(range(len(t)), t))\n",
    "        splits = np.delete(splits, no_label_element_index,0) \n",
    "        Y.extend(splits)\n",
    "\n",
    "        img = seismic[i]\n",
    "        splits = split_Image(img, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,hori_splits_number)\n",
    "        splits = np.delete(splits, no_label_element_index,0)\n",
    "        X.extend(splits)\n",
    "\n",
    "    print(len(Y))\n",
    "    print(len(X))\n",
    "    print(X[0].shape)\n",
    "    print(\"read images in {} sec\".format(time.time()-t_start))\n",
    "    \n",
    "    #creating directory if not already made, else leave it as it is\n",
    "    directory = \"{}/{}/seismic\".format(processed_data_folder,data_type)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    directory = \"{}/{}/annotation\".format(processed_data_folder,data_type)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    #saving all_images as a single npy\n",
    "    np.save(\"{}/{}/seismic.npy\".format(processed_data_folder, data_type),X)\n",
    "    np.save(\"{}/{}/annotation.npy\".format(processed_data_folder, data_type),Y)\n",
    "    \n",
    "    #saving_individual_images as npy\n",
    "    for i in range(len(X)):\n",
    "        np.save(\"{}/{}/seismic/{}.npy\".format(processed_data_folder, data_type,i),X[i])\n",
    "        np.save(\"{}/{}/annotation/{}.npy\".format(processed_data_folder, data_type,i),Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8913b348-3aeb-4ceb-9912-cf814536f2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reading......\n",
      "load in 10.301100730895996 sec\n",
      "(50, 1537, 3174) (50, 1537, 3174)\n",
      "1.0 0.0 True False\n",
      "491\n",
      "horizontal_splits_number 33\n",
      "width_after_pad 3200\n",
      "left_pad,right_pad 13 13\n",
      "vertical_splits_number 16\n",
      "height_after_pad 1568\n",
      "top_pad,bottom_pad 15 16\n",
      "2894\n",
      "2894\n",
      "(128, 128)\n",
      "read images in 1.0883738994598389 sec\n"
     ]
    }
   ],
   "source": [
    "#processing_training_data\n",
    "process_raw_data('train', 'trainseis', 'trainfault', 128, 96,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67855f43-d714-4a7c-ae43-13267f1aba59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reading......\n",
      "load in 2.0827808380126953 sec\n",
      "(30, 1537, 3174) (30, 1537, 3174)\n",
      "1.0 0.0 True False\n",
      "7864\n",
      "horizontal_splits_number 12\n",
      "width_after_pad 3328\n",
      "left_pad,right_pad 77 77\n",
      "vertical_splits_number 6\n",
      "height_after_pad 1792\n",
      "top_pad,bottom_pad 127 128\n",
      "360\n",
      "360\n",
      "(512, 512)\n",
      "read images in 1.5873818397521973 sec\n"
     ]
    }
   ],
   "source": [
    "#processing_validation_data\n",
    "process_raw_data('val', 'valseis', 'valfault', 512, 256,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06ef33d3-ab17-4901-b7e9-c280332ae5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started reading\n",
      "loaded data in 0.1453409194946289 sec\n",
      "(20, 1537, 3174) (20, 1537, 3174)\n",
      "1.0 0.0 True False\n",
      "hori_splits_number 11\n",
      "width_after_pad 3328\n",
      "left_pad,right_pad 77 77\n",
      "vertical_splits_number 5\n",
      "height_after_pad 1792\n",
      "top_pad,bottom_pad 127 128\n",
      "295\n",
      "295\n",
      "(768, 768)\n",
      "read images in 2.6631052494049072 sec\n"
     ]
    }
   ],
   "source": [
    "#processing_test_data\n",
    "process_raw_data('test', 'testseis', 'testfault', 768, 256,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9737ddc3-3aa0-484c-ab04-607c0783c2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saves the image for viewing training, validation and test set\n",
    "def show_image(i,data_type):\n",
    "    seis = np.load(\"{}/{}/seismic/{}.npy\".format('./processed_data', data_type, i))\n",
    "    mask = np.load(\"{}/{}/annotation/{}.npy\".format('./processed_data', data_type, i))\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.imshow(seis,'gray')\n",
    "    plt.imshow(mask, 'gray', alpha=0.4)\n",
    "    plt.savefig(\"{}myfilename.png\".format(data_type), dpi=200)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2ebfe04-2a4a-4b70-b1b6-38d6bd9a189e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_image(12,'train')\n",
    "show_image(12,'val')\n",
    "show_image(12,'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
